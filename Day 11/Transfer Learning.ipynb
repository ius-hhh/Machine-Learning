{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aadf8ea",
   "metadata": {},
   "source": [
    "# üß† Day 11 ‚Äì Image Classification with Transfer Learning\n",
    "\n",
    " üìå In this project, we aim to:\n",
    " - Use a pretrained CNN (like VGG16 or ResNet50) for image classification.\n",
    " - Learn how to freeze layers and fine-tune top layers.\n",
    " - Load image data using ImageDataGenerator.\n",
    " - Evaluate performance using accuracy, loss, and confusion matrix.\n",
    " ‚úÖ We‚Äôll use a subset of the Dogs vs Cats dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e1d29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 1: Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ca8541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\Programming\\Machine-Learning\\Day 11\n",
      "Folders in current directory:\n",
      "['cats_and_dogs_filtered', 'Transfer Learning.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Folders in current directory:\")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b9ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Cats: ['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.101.jpg']\n",
      "‚úÖ Train Dogs: ['dog.0.jpg', 'dog.1.jpg', 'dog.10.jpg', 'dog.100.jpg', 'dog.101.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Correct base directory (based on confirmed structure)\n",
    "base_dir = os.path.join(os.getcwd(), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Confirm folder contents\n",
    "print(\"‚úÖ Train Cats:\", os.listdir(os.path.join(train_dir, 'cats'))[:5])\n",
    "print(\"‚úÖ Train Dogs:\", os.listdir(os.path.join(train_dir, 'dogs'))[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c4d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size and batch size\n",
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training data generator with rescaling (can augmentation here later)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Validation data generator just rescales\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create train generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'   # because we have two classes (cats and dogs)\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ba1bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the VGG16 model, excluding the top classification layer\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',         # Use pretrained weights\n",
    "    include_top=False,          # Do NOT include the dense layers at the top\n",
    "    input_shape=(160, 160, 3)   # Input shape must match our resized images\n",
    ")\n",
    "\n",
    "# Freeze the entire base model so its weights don't change during training\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "380b7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output of the base model\n",
    "x = base_model.output\n",
    "\n",
    "# Flatten the 3D feature maps into 1D\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Add a fully connected (dense) layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# Add dropout for regularization (prevents overfitting)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add the final output layer (binary classification: cat or dog)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
